# Data Science and Machine Learning Course (2 Months)

This course covers fundamental models and techniques in Data Science and Machine Learning, focusing on when and how to use each model effectively. The course is structured over 8 weeks, with hands-on projects in each week.

## Week 1: Introduction to Data Science and Python
- **Data Science Overview**
  - What is Data Science?
  - Importance of Data in Business and Research
  - Data Science Workflow: Collecting, Cleaning, Analyzing, Visualizing, and Modeling
- **Python for Data Science**
  - Introduction to Python Libraries: NumPy, Pandas, Matplotlib, Seaborn
  - Data Manipulation with Pandas
  - Data Visualization Basics
- **Project**: Exploratory Data Analysis (EDA) on a Sample Dataset

## Week 2: Supervised Learning – Regression
- **Linear Regression**
  - Simple Linear Regression, Multiple Linear Regression
  - Assumptions, Interpretation of Coefficients
  - Evaluation Metrics: RMSE, R²
- **Polynomial Regression**
  - When to Use Polynomial over Linear Regression
- **Regularization Techniques**
  - Ridge and Lasso Regression, Elastic Net
  - Preventing Overfitting
- **Project**: Predicting House Prices using Linear Regression

## Week 3: Supervised Learning – Classification
- **Logistic Regression**
  - Binary Classification, Sigmoid Function
  - Evaluation Metrics: Accuracy, Precision, Recall, F1-Score, AUC-ROC Curve
- **Decision Trees**
  - Splitting Criteria, Gini Impurity, and Entropy
  - Advantages and Disadvantages
- **Random Forests**
  - Ensemble Learning, Bagging, Feature Importance
- **Project**: Binary Classification of Loan Default Prediction

## Week 4: Supervised Learning – Advanced Classification Models
- **Support Vector Machines (SVM)**
  - Hyperplanes, Margin, and Support Vectors
  - Kernel Trick and Non-linear Boundaries
- **K-Nearest Neighbors (KNN)**
  - Distance Metrics, K-Value Selection, Lazy Learning
  - Use Cases of KNN
- **Naive Bayes**
  - Probabilistic Classifier, Assumptions, Types (Gaussian, Multinomial)
  - Use Cases for Text Classification
- **Project**: Multi-class Classification using SVM and KNN

## Week 5: Unsupervised Learning – Clustering and Dimensionality Reduction
- **K-Means Clustering**
  - Centroids, Distance Metrics, Elbow Method for Optimal Clusters
  - Use Cases: Customer Segmentation
- **Hierarchical Clustering**
  - Agglomerative and Divisive Approaches
  - Dendrograms
- **Dimensionality Reduction**
  - Principal Component Analysis (PCA)
  - Use Cases of PCA
- **Project**: Customer Segmentation using K-Means and Hierarchical Clustering

## Week 6: Unsupervised Learning – Anomaly Detection and Association Rules
- **Anomaly Detection**
  - Z-Score, IQR, Isolation Forest, One-Class SVM
  - Use Cases: Fraud Detection, Outlier Detection
- **Association Rule Mining**
  - Apriori Algorithm, Support, Confidence, Lift
  - Use Cases: Market Basket Analysis
- **Project**: Fraud Detection using Isolation Forest

## Week 7: Model Evaluation and Hyperparameter Tuning
- **Model Evaluation Techniques**
  - Cross-Validation (K-Fold, Leave-One-Out)
  - Bias-Variance Tradeoff
  - Confusion Matrix, Precision-Recall Curve
- **Hyperparameter Tuning**
  - Grid Search, Random Search
  - Using Scikit-learn for Tuning
- **Project**: Tuning Hyperparameters of Random Forest on a Classification Problem

## Week 8: Deep Learning Basics and Time Series
- **Introduction to Neural Networks**
  - Perceptron, Activation Functions (ReLU, Sigmoid, Softmax)
  - Backpropagation, Gradient Descent
- **Time Series Analysis**
  - Trend, Seasonality, ARIMA, SARIMA
  - Evaluation of Time Series Models
- **Project**: Stock Price Prediction using ARIMA and Neural Networks

---

Each week focuses on a specific topic with real-world projects and hands-on practice.
